/*
    This file is part of the WebKit open source project.
    This file has been generated by generate-bindings.pl. DO NOT MODIFY!

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Library General Public
    License as published by the Free Software Foundation; either
    version 2 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Library General Public License for more details.

    You should have received a copy of the GNU Library General Public License
    along with this library; see the file COPYING.LIB.  If not, write to
    the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA 02110-1301, USA.
*/

#include "config.h"

#if ENABLE(WEB_AUDIO)

#include "JSAudioContext.h"

#include "Document.h"
#include "EventNames.h"
#include "JSAnalyserNode.h"
#include "JSAudioBuffer.h"
#include "JSAudioBufferCallback.h"
#include "JSAudioBufferSourceNode.h"
#include "JSAudioDestinationNode.h"
#include "JSAudioListener.h"
#include "JSBiquadFilterNode.h"
#include "JSChannelMergerNode.h"
#include "JSChannelSplitterNode.h"
#include "JSConvolverNode.h"
#include "JSDOMBinding.h"
#include "JSDOMConstructor.h"
#include "JSDOMPromise.h"
#include "JSDelayNode.h"
#include "JSDynamicsCompressorNode.h"
#include "JSEventListener.h"
#include "JSGainNode.h"
#include "JSMediaElementAudioSourceNode.h"
#include "JSMediaStreamAudioDestinationNode.h"
#include "JSMediaStreamAudioSourceNode.h"
#include "JSOscillatorNode.h"
#include "JSPannerNode.h"
#include "JSPeriodicWave.h"
#include "JSScriptProcessorNode.h"
#include "JSWaveShaperNode.h"
#include <runtime/Error.h>
#include <runtime/JSString.h>
#include <wtf/GetPtr.h>

#if ENABLE(MEDIA_STREAM)
#include "JSMediaStream.h"
#endif

#if ENABLE(VIDEO)
#include "JSHTMLMediaElement.h"
#endif

using namespace JSC;

namespace WebCore {

template<> JSString* convertEnumerationToJS(ExecState& state, AudioContext::State enumerationValue)
{
    static NeverDestroyed<const String> values[] = {
        ASCIILiteral("suspended"),
        ASCIILiteral("running"),
        ASCIILiteral("interrupted"),
        ASCIILiteral("closed"),
    };
    static_assert(static_cast<size_t>(AudioContext::State::Suspended) == 0, "AudioContext::State::Suspended is not 0 as expected");
    static_assert(static_cast<size_t>(AudioContext::State::Running) == 1, "AudioContext::State::Running is not 1 as expected");
    static_assert(static_cast<size_t>(AudioContext::State::Interrupted) == 2, "AudioContext::State::Interrupted is not 2 as expected");
    static_assert(static_cast<size_t>(AudioContext::State::Closed) == 3, "AudioContext::State::Closed is not 3 as expected");
    ASSERT(static_cast<size_t>(enumerationValue) < WTF_ARRAY_LENGTH(values));
    return jsStringWithCache(&state, values[static_cast<size_t>(enumerationValue)]);
}

template<> std::optional<AudioContext::State> parseEnumeration<AudioContext::State>(ExecState& state, JSValue value)
{
    auto stringValue = value.toWTFString(&state);
    if (stringValue == "suspended")
        return AudioContext::State::Suspended;
    if (stringValue == "running")
        return AudioContext::State::Running;
    if (stringValue == "interrupted")
        return AudioContext::State::Interrupted;
    if (stringValue == "closed")
        return AudioContext::State::Closed;
    return std::nullopt;
}

template<> AudioContext::State convertEnumeration<AudioContext::State>(ExecState& state, JSValue value)
{
    VM& vm = state.vm();
    auto throwScope = DECLARE_THROW_SCOPE(vm);
    auto result = parseEnumeration<AudioContext::State>(state, value);
    if (UNLIKELY(!result)) {
        throwTypeError(&state, throwScope);
        return { };
    }
    return result.value();
}

template<> const char* expectedEnumerationValues<AudioContext::State>()
{
    return "\"suspended\", \"running\", \"interrupted\", \"closed\"";
}

// Functions

JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionSuspend(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionResume(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionClose(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateBuffer(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionDecodeAudioData(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateBufferSource(JSC::ExecState*);
#if ENABLE(VIDEO)
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateMediaElementSource(JSC::ExecState*);
#endif
#if ENABLE(MEDIA_STREAM)
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateMediaStreamSource(JSC::ExecState*);
#endif
#if ENABLE(MEDIA_STREAM)
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateMediaStreamDestination(JSC::ExecState*);
#endif
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateGain(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateDelay(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateBiquadFilter(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateWaveShaper(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreatePanner(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateConvolver(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateDynamicsCompressor(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateAnalyser(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateScriptProcessor(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateOscillator(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreatePeriodicWave(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateChannelSplitter(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateChannelMerger(JSC::ExecState*);
JSC::EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionStartRendering(JSC::ExecState*);

// Attributes

JSC::EncodedJSValue jsAudioContextDestination(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
JSC::EncodedJSValue jsAudioContextCurrentTime(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
JSC::EncodedJSValue jsAudioContextSampleRate(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
JSC::EncodedJSValue jsAudioContextListener(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
JSC::EncodedJSValue jsAudioContextState(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
JSC::EncodedJSValue jsAudioContextOnstatechange(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
bool setJSAudioContextOnstatechange(JSC::ExecState*, JSC::EncodedJSValue, JSC::EncodedJSValue);
JSC::EncodedJSValue jsAudioContextActiveSourceCount(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
JSC::EncodedJSValue jsAudioContextOncomplete(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
bool setJSAudioContextOncomplete(JSC::ExecState*, JSC::EncodedJSValue, JSC::EncodedJSValue);
JSC::EncodedJSValue jsAudioContextConstructor(JSC::ExecState*, JSC::EncodedJSValue, JSC::PropertyName);
bool setJSAudioContextConstructor(JSC::ExecState*, JSC::EncodedJSValue, JSC::EncodedJSValue);

class JSAudioContextPrototype : public JSC::JSNonFinalObject {
public:
    using Base = JSC::JSNonFinalObject;
    static JSAudioContextPrototype* create(JSC::VM& vm, JSC::JSGlobalObject* globalObject, JSC::Structure* structure)
    {
        JSAudioContextPrototype* ptr = new (NotNull, JSC::allocateCell<JSAudioContextPrototype>(vm.heap)) JSAudioContextPrototype(vm, globalObject, structure);
        ptr->finishCreation(vm);
        return ptr;
    }

    DECLARE_INFO;
    static JSC::Structure* createStructure(JSC::VM& vm, JSC::JSGlobalObject* globalObject, JSC::JSValue prototype)
    {
        return JSC::Structure::create(vm, globalObject, prototype, JSC::TypeInfo(JSC::ObjectType, StructureFlags), info());
    }

private:
    JSAudioContextPrototype(JSC::VM& vm, JSC::JSGlobalObject*, JSC::Structure* structure)
        : JSC::JSNonFinalObject(vm, structure)
    {
    }

    void finishCreation(JSC::VM&);
};

using JSAudioContextConstructor = JSDOMConstructor<JSAudioContext>;

template<> EncodedJSValue JSC_HOST_CALL JSAudioContextConstructor::construct(ExecState* state)
{
    VM& vm = state->vm();
    auto throwScope = DECLARE_THROW_SCOPE(vm);
    UNUSED_PARAM(throwScope);
    auto* castedThis = jsCast<JSAudioContextConstructor*>(state->jsCallee());
    ASSERT(castedThis);
    ScriptExecutionContext* context = castedThis->scriptExecutionContext();
    if (UNLIKELY(!context))
        return throwConstructorScriptExecutionContextUnavailableError(*state, throwScope, "webkitAudioContext");
    ASSERT(context->isDocument());
    auto& document = downcast<Document>(*context);
    auto object = AudioContext::create(document);
    return JSValue::encode(toJSNewlyCreated<IDLInterface<AudioContext>>(*state, *castedThis->globalObject(), WTFMove(object)));
}

template<> JSValue JSAudioContextConstructor::prototypeForStructure(JSC::VM& vm, const JSDOMGlobalObject& globalObject)
{
    return JSEventTarget::getConstructor(vm, &globalObject);
}

template<> void JSAudioContextConstructor::initializeProperties(VM& vm, JSDOMGlobalObject& globalObject)
{
    putDirect(vm, vm.propertyNames->prototype, JSAudioContext::prototype(vm, &globalObject), DontDelete | ReadOnly | DontEnum);
    putDirect(vm, vm.propertyNames->name, jsNontrivialString(&vm, String(ASCIILiteral("webkitAudioContext"))), ReadOnly | DontEnum);
    putDirect(vm, vm.propertyNames->length, jsNumber(0), ReadOnly | DontEnum);
}

template<> const ClassInfo JSAudioContextConstructor::s_info = { "webkitAudioContext", &Base::s_info, 0, CREATE_METHOD_TABLE(JSAudioContextConstructor) };

/* Hash table for prototype */

static const HashTableValue JSAudioContextPrototypeTableValues[] =
{
    { "constructor", DontEnum, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextConstructor), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(setJSAudioContextConstructor) } },
    { "destination", ReadOnly | CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextDestination), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(0) } },
    { "currentTime", ReadOnly | CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextCurrentTime), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(0) } },
    { "sampleRate", ReadOnly | CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextSampleRate), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(0) } },
    { "listener", ReadOnly | CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextListener), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(0) } },
    { "state", ReadOnly | CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextState), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(0) } },
    { "onstatechange", CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextOnstatechange), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(setJSAudioContextOnstatechange) } },
    { "activeSourceCount", ReadOnly | CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextActiveSourceCount), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(0) } },
    { "oncomplete", CustomAccessor, NoIntrinsic, { (intptr_t)static_cast<PropertySlot::GetValueFunc>(jsAudioContextOncomplete), (intptr_t) static_cast<PutPropertySlot::PutValueFunc>(setJSAudioContextOncomplete) } },
    { "suspend", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionSuspend), (intptr_t) (0) } },
    { "resume", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionResume), (intptr_t) (0) } },
    { "close", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionClose), (intptr_t) (0) } },
    { "createBuffer", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateBuffer), (intptr_t) (2) } },
    { "decodeAudioData", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionDecodeAudioData), (intptr_t) (2) } },
    { "createBufferSource", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateBufferSource), (intptr_t) (0) } },
#if ENABLE(VIDEO)
    { "createMediaElementSource", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateMediaElementSource), (intptr_t) (1) } },
#else
    { 0, 0, NoIntrinsic, { 0, 0 } },
#endif
#if ENABLE(MEDIA_STREAM)
    { "createMediaStreamSource", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateMediaStreamSource), (intptr_t) (1) } },
#else
    { 0, 0, NoIntrinsic, { 0, 0 } },
#endif
#if ENABLE(MEDIA_STREAM)
    { "createMediaStreamDestination", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateMediaStreamDestination), (intptr_t) (0) } },
#else
    { 0, 0, NoIntrinsic, { 0, 0 } },
#endif
    { "createGain", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateGain), (intptr_t) (0) } },
    { "createDelay", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateDelay), (intptr_t) (0) } },
    { "createBiquadFilter", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateBiquadFilter), (intptr_t) (0) } },
    { "createWaveShaper", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateWaveShaper), (intptr_t) (0) } },
    { "createPanner", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreatePanner), (intptr_t) (0) } },
    { "createConvolver", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateConvolver), (intptr_t) (0) } },
    { "createDynamicsCompressor", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateDynamicsCompressor), (intptr_t) (0) } },
    { "createAnalyser", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateAnalyser), (intptr_t) (0) } },
    { "createScriptProcessor", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateScriptProcessor), (intptr_t) (1) } },
    { "createOscillator", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateOscillator), (intptr_t) (0) } },
    { "createPeriodicWave", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreatePeriodicWave), (intptr_t) (2) } },
    { "createChannelSplitter", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateChannelSplitter), (intptr_t) (0) } },
    { "createChannelMerger", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionCreateChannelMerger), (intptr_t) (0) } },
    { "startRendering", JSC::Function, NoIntrinsic, { (intptr_t)static_cast<NativeFunction>(jsAudioContextPrototypeFunctionStartRendering), (intptr_t) (0) } },
};

const ClassInfo JSAudioContextPrototype::s_info = { "webkitAudioContextPrototype", &Base::s_info, 0, CREATE_METHOD_TABLE(JSAudioContextPrototype) };

void JSAudioContextPrototype::finishCreation(VM& vm)
{
    Base::finishCreation(vm);
    reifyStaticProperties(vm, JSAudioContextPrototypeTableValues, *this);
}

const ClassInfo JSAudioContext::s_info = { "webkitAudioContext", &Base::s_info, 0, CREATE_METHOD_TABLE(JSAudioContext) };

JSAudioContext::JSAudioContext(Structure* structure, JSDOMGlobalObject& globalObject, Ref<AudioContext>&& impl)
    : JSEventTarget(structure, globalObject, WTFMove(impl))
{
}

void JSAudioContext::finishCreation(VM& vm)
{
    Base::finishCreation(vm);
    ASSERT(inherits(info()));

}

JSObject* JSAudioContext::createPrototype(VM& vm, JSGlobalObject* globalObject)
{
    return JSAudioContextPrototype::create(vm, globalObject, JSAudioContextPrototype::createStructure(vm, globalObject, JSEventTarget::prototype(vm, globalObject)));
}

JSObject* JSAudioContext::prototype(VM& vm, JSGlobalObject* globalObject)
{
    return getDOMPrototype<JSAudioContext>(vm, globalObject);
}

template<> inline JSAudioContext* BindingCaller<JSAudioContext>::castForAttribute(ExecState&, EncodedJSValue thisValue)
{
    return jsDynamicDowncast<JSAudioContext*>(JSValue::decode(thisValue));
}

template<> inline JSAudioContext* BindingCaller<JSAudioContext>::castForOperation(ExecState& state)
{
    return jsDynamicDowncast<JSAudioContext*>(state.thisValue());
}

static inline JSValue jsAudioContextDestinationGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextDestination(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextDestinationGetter>(state, thisValue, "destination");
}

static inline JSValue jsAudioContextDestinationGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    auto& impl = thisObject.wrapped();
    JSValue result = toJS<IDLInterface<AudioDestinationNode>>(state, *thisObject.globalObject(), impl.destination());
    return result;
}

static inline JSValue jsAudioContextCurrentTimeGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextCurrentTime(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextCurrentTimeGetter>(state, thisValue, "currentTime");
}

static inline JSValue jsAudioContextCurrentTimeGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    auto& impl = thisObject.wrapped();
    JSValue result = toJS<IDLUnrestrictedDouble>(impl.currentTime());
    return result;
}

static inline JSValue jsAudioContextSampleRateGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextSampleRate(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextSampleRateGetter>(state, thisValue, "sampleRate");
}

static inline JSValue jsAudioContextSampleRateGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    auto& impl = thisObject.wrapped();
    JSValue result = toJS<IDLUnrestrictedFloat>(impl.sampleRate());
    return result;
}

static inline JSValue jsAudioContextListenerGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextListener(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextListenerGetter>(state, thisValue, "listener");
}

static inline JSValue jsAudioContextListenerGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    auto& impl = thisObject.wrapped();
    JSValue result = toJS<IDLInterface<AudioListener>>(state, *thisObject.globalObject(), impl.listener());
    return result;
}

static inline JSValue jsAudioContextStateGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextState(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextStateGetter>(state, thisValue, "state");
}

static inline JSValue jsAudioContextStateGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    auto& impl = thisObject.wrapped();
    JSValue result = toJS<IDLEnumeration<AudioContext::State>>(state, impl.state());
    return result;
}

static inline JSValue jsAudioContextOnstatechangeGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextOnstatechange(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextOnstatechangeGetter>(state, thisValue, "onstatechange");
}

static inline JSValue jsAudioContextOnstatechangeGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    return eventHandlerAttribute(thisObject.wrapped(), eventNames().statechangeEvent);
}

static inline JSValue jsAudioContextActiveSourceCountGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextActiveSourceCount(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextActiveSourceCountGetter>(state, thisValue, "activeSourceCount");
}

static inline JSValue jsAudioContextActiveSourceCountGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    auto& impl = thisObject.wrapped();
    JSValue result = toJS<IDLUnsignedLong>(impl.activeSourceCount());
    return result;
}

static inline JSValue jsAudioContextOncompleteGetter(ExecState&, JSAudioContext&, ThrowScope& throwScope);

EncodedJSValue jsAudioContextOncomplete(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    return BindingCaller<JSAudioContext>::attribute<jsAudioContextOncompleteGetter>(state, thisValue, "oncomplete");
}

static inline JSValue jsAudioContextOncompleteGetter(ExecState& state, JSAudioContext& thisObject, ThrowScope& throwScope)
{
    UNUSED_PARAM(throwScope);
    UNUSED_PARAM(state);
    return eventHandlerAttribute(thisObject.wrapped(), eventNames().completeEvent);
}

EncodedJSValue jsAudioContextConstructor(ExecState* state, EncodedJSValue thisValue, PropertyName)
{
    VM& vm = state->vm();
    auto throwScope = DECLARE_THROW_SCOPE(vm);
    JSAudioContextPrototype* domObject = jsDynamicDowncast<JSAudioContextPrototype*>(JSValue::decode(thisValue));
    if (UNLIKELY(!domObject))
        return throwVMTypeError(state, throwScope);
    return JSValue::encode(JSAudioContext::getConstructor(state->vm(), domObject->globalObject()));
}

bool setJSAudioContextConstructor(ExecState* state, EncodedJSValue thisValue, EncodedJSValue encodedValue)
{
    VM& vm = state->vm();
    auto throwScope = DECLARE_THROW_SCOPE(vm);
    JSValue value = JSValue::decode(encodedValue);
    JSAudioContextPrototype* domObject = jsDynamicDowncast<JSAudioContextPrototype*>(JSValue::decode(thisValue));
    if (UNLIKELY(!domObject)) {
        throwVMTypeError(state, throwScope);
        return false;
    }
    // Shadowing a built-in constructor
    return domObject->putDirect(state->vm(), state->propertyNames().constructor, value);
}

static inline bool setJSAudioContextOnstatechangeFunction(ExecState&, JSAudioContext&, JSValue, ThrowScope&);

bool setJSAudioContextOnstatechange(ExecState* state, EncodedJSValue thisValue, EncodedJSValue encodedValue)
{
    return BindingCaller<JSAudioContext>::setAttribute<setJSAudioContextOnstatechangeFunction>(state, thisValue, encodedValue, "onstatechange");
}

static inline bool setJSAudioContextOnstatechangeFunction(ExecState& state, JSAudioContext& thisObject, JSValue value, ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    setEventHandlerAttribute(state, thisObject, thisObject.wrapped(), eventNames().statechangeEvent, value);
    return true;
}


static inline bool setJSAudioContextOncompleteFunction(ExecState&, JSAudioContext&, JSValue, ThrowScope&);

bool setJSAudioContextOncomplete(ExecState* state, EncodedJSValue thisValue, EncodedJSValue encodedValue)
{
    return BindingCaller<JSAudioContext>::setAttribute<setJSAudioContextOncompleteFunction>(state, thisValue, encodedValue, "oncomplete");
}

static inline bool setJSAudioContextOncompleteFunction(ExecState& state, JSAudioContext& thisObject, JSValue value, ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    setEventHandlerAttribute(state, thisObject, thisObject.wrapped(), eventNames().completeEvent, value);
    return true;
}


JSValue JSAudioContext::getConstructor(VM& vm, const JSGlobalObject* globalObject)
{
    return getDOMConstructor<JSAudioContextConstructor>(vm, *jsCast<const JSDOMGlobalObject*>(globalObject));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionSuspendCaller(JSC::ExecState*, JSAudioContext*, Ref<DeferredPromise>&&, JSC::ThrowScope&);

static EncodedJSValue jsAudioContextPrototypeFunctionSuspendPromise(ExecState*, Ref<DeferredPromise>&&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionSuspend(ExecState* state)
{
    ASSERT(state);
    return JSValue::encode(callPromiseFunction<jsAudioContextPrototypeFunctionSuspendPromise, PromiseExecutionScope::WindowOnly>(*state));
}

static inline EncodedJSValue jsAudioContextPrototypeFunctionSuspendPromise(ExecState* state, Ref<DeferredPromise>&& promise)
{
    return BindingCaller<JSAudioContext>::callPromiseOperation<jsAudioContextPrototypeFunctionSuspendCaller>(state, WTFMove(promise), "suspend");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionSuspendCaller(JSC::ExecState* state, JSAudioContext* castedThis, Ref<DeferredPromise>&& promise, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    impl.suspend(WTFMove(promise));
    return JSValue::encode(jsUndefined());
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionResumeCaller(JSC::ExecState*, JSAudioContext*, Ref<DeferredPromise>&&, JSC::ThrowScope&);

static EncodedJSValue jsAudioContextPrototypeFunctionResumePromise(ExecState*, Ref<DeferredPromise>&&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionResume(ExecState* state)
{
    ASSERT(state);
    return JSValue::encode(callPromiseFunction<jsAudioContextPrototypeFunctionResumePromise, PromiseExecutionScope::WindowOnly>(*state));
}

static inline EncodedJSValue jsAudioContextPrototypeFunctionResumePromise(ExecState* state, Ref<DeferredPromise>&& promise)
{
    return BindingCaller<JSAudioContext>::callPromiseOperation<jsAudioContextPrototypeFunctionResumeCaller>(state, WTFMove(promise), "resume");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionResumeCaller(JSC::ExecState* state, JSAudioContext* castedThis, Ref<DeferredPromise>&& promise, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    impl.resume(WTFMove(promise));
    return JSValue::encode(jsUndefined());
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCloseCaller(JSC::ExecState*, JSAudioContext*, Ref<DeferredPromise>&&, JSC::ThrowScope&);

static EncodedJSValue jsAudioContextPrototypeFunctionClosePromise(ExecState*, Ref<DeferredPromise>&&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionClose(ExecState* state)
{
    ASSERT(state);
    return JSValue::encode(callPromiseFunction<jsAudioContextPrototypeFunctionClosePromise, PromiseExecutionScope::WindowOnly>(*state));
}

static inline EncodedJSValue jsAudioContextPrototypeFunctionClosePromise(ExecState* state, Ref<DeferredPromise>&& promise)
{
    return BindingCaller<JSAudioContext>::callPromiseOperation<jsAudioContextPrototypeFunctionCloseCaller>(state, WTFMove(promise), "close");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCloseCaller(JSC::ExecState* state, JSAudioContext* castedThis, Ref<DeferredPromise>&& promise, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    impl.close(WTFMove(promise));
    return JSValue::encode(jsUndefined());
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBuffer1Caller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

static inline EncodedJSValue jsAudioContextPrototypeFunctionCreateBuffer1(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateBuffer1Caller>(state, "createBuffer");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBuffer1Caller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 3))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto numberOfChannels = convert<IDLUnsignedLong>(*state, state->uncheckedArgument(0), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto numberOfFrames = convert<IDLUnsignedLong>(*state, state->uncheckedArgument(1), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto sampleRate = convert<IDLUnrestrictedFloat>(*state, state->uncheckedArgument(2));
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<AudioBuffer>>(*state, *castedThis->globalObject(), throwScope, impl.createBuffer(WTFMove(numberOfChannels), WTFMove(numberOfFrames), WTFMove(sampleRate))));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBuffer2Caller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

static inline EncodedJSValue jsAudioContextPrototypeFunctionCreateBuffer2(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateBuffer2Caller>(state, "createBuffer");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBuffer2Caller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 2))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto buffer = convert<IDLInterface<ArrayBuffer>>(*state, state->uncheckedArgument(0), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentTypeError(state, scope, 0, "buffer", "webkitAudioContext", "createBuffer", "ArrayBuffer"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto mixToMono = convert<IDLBoolean>(*state, state->uncheckedArgument(1));
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<AudioBuffer>>(*state, *castedThis->globalObject(), throwScope, impl.createBuffer(*buffer, WTFMove(mixToMono))));
}

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateBuffer(ExecState* state)
{
    VM& vm = state->vm();
    auto throwScope = DECLARE_THROW_SCOPE(vm);
    UNUSED_PARAM(throwScope);
    size_t argsCount = std::min<size_t>(3, state->argumentCount());
    if (argsCount == 2) {
        return jsAudioContextPrototypeFunctionCreateBuffer2(state);
    }
    if (argsCount == 3) {
        return jsAudioContextPrototypeFunctionCreateBuffer1(state);
    }
    return argsCount < 2 ? throwVMError(state, throwScope, createNotEnoughArgumentsError(state)) : throwVMTypeError(state, throwScope);
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionDecodeAudioDataCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionDecodeAudioData(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionDecodeAudioDataCaller>(state, "decodeAudioData");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionDecodeAudioDataCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 2))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto audioData = convert<IDLInterface<ArrayBuffer>>(*state, state->uncheckedArgument(0), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentTypeError(state, scope, 0, "audioData", "webkitAudioContext", "decodeAudioData", "ArrayBuffer"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto successCallback = convert<IDLNullable<IDLCallbackFunction<JSAudioBufferCallback>>>(*state, state->uncheckedArgument(1), *castedThis->globalObject(), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentMustBeFunctionError(state, scope, 1, "successCallback", "webkitAudioContext", "decodeAudioData"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto errorCallback = convert<IDLNullable<IDLCallbackFunction<JSAudioBufferCallback>>>(*state, state->argument(2), *castedThis->globalObject(), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentMustBeFunctionError(state, scope, 2, "errorCallback", "webkitAudioContext", "decodeAudioData"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    impl.decodeAudioData(*audioData, WTFMove(successCallback), WTFMove(errorCallback));
    return JSValue::encode(jsUndefined());
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBufferSourceCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateBufferSource(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateBufferSourceCaller>(state, "createBufferSource");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBufferSourceCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<AudioBufferSourceNode>>(*state, *castedThis->globalObject(), impl.createBufferSource()));
}

#if ENABLE(VIDEO)
static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateMediaElementSourceCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateMediaElementSource(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateMediaElementSourceCaller>(state, "createMediaElementSource");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateMediaElementSourceCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 1))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto mediaElement = convert<IDLInterface<HTMLMediaElement>>(*state, state->uncheckedArgument(0), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentTypeError(state, scope, 0, "mediaElement", "webkitAudioContext", "createMediaElementSource", "HTMLMediaElement"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<MediaElementAudioSourceNode>>(*state, *castedThis->globalObject(), throwScope, impl.createMediaElementSource(*mediaElement)));
}

#endif

#if ENABLE(MEDIA_STREAM)
static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateMediaStreamSourceCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateMediaStreamSource(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateMediaStreamSourceCaller>(state, "createMediaStreamSource");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateMediaStreamSourceCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 1))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto mediaStream = convert<IDLInterface<MediaStream>>(*state, state->uncheckedArgument(0), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentTypeError(state, scope, 0, "mediaStream", "webkitAudioContext", "createMediaStreamSource", "MediaStream"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<MediaStreamAudioSourceNode>>(*state, *castedThis->globalObject(), throwScope, impl.createMediaStreamSource(*mediaStream)));
}

#endif

#if ENABLE(MEDIA_STREAM)
static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateMediaStreamDestinationCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateMediaStreamDestination(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateMediaStreamDestinationCaller>(state, "createMediaStreamDestination");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateMediaStreamDestinationCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<MediaStreamAudioDestinationNode>>(*state, *castedThis->globalObject(), impl.createMediaStreamDestination()));
}

#endif

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateGainCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateGain(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateGainCaller>(state, "createGain");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateGainCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<GainNode>>(*state, *castedThis->globalObject(), impl.createGain()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateDelayCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateDelay(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateDelayCaller>(state, "createDelay");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateDelayCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    auto maxDelayTime = state->argument(0).isUndefined() ? 1 : convert<IDLUnrestrictedDouble>(*state, state->uncheckedArgument(0));
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<DelayNode>>(*state, *castedThis->globalObject(), throwScope, impl.createDelay(WTFMove(maxDelayTime))));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBiquadFilterCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateBiquadFilter(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateBiquadFilterCaller>(state, "createBiquadFilter");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateBiquadFilterCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<BiquadFilterNode>>(*state, *castedThis->globalObject(), impl.createBiquadFilter()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateWaveShaperCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateWaveShaper(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateWaveShaperCaller>(state, "createWaveShaper");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateWaveShaperCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<WaveShaperNode>>(*state, *castedThis->globalObject(), impl.createWaveShaper()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreatePannerCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreatePanner(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreatePannerCaller>(state, "createPanner");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreatePannerCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<PannerNode>>(*state, *castedThis->globalObject(), impl.createPanner()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateConvolverCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateConvolver(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateConvolverCaller>(state, "createConvolver");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateConvolverCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<ConvolverNode>>(*state, *castedThis->globalObject(), impl.createConvolver()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateDynamicsCompressorCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateDynamicsCompressor(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateDynamicsCompressorCaller>(state, "createDynamicsCompressor");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateDynamicsCompressorCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<DynamicsCompressorNode>>(*state, *castedThis->globalObject(), impl.createDynamicsCompressor()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateAnalyserCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateAnalyser(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateAnalyserCaller>(state, "createAnalyser");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateAnalyserCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<AnalyserNode>>(*state, *castedThis->globalObject(), impl.createAnalyser()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateScriptProcessorCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateScriptProcessor(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateScriptProcessorCaller>(state, "createScriptProcessor");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateScriptProcessorCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 1))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto bufferSize = convert<IDLUnsignedLong>(*state, state->uncheckedArgument(0), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto numberOfInputChannels = state->argument(1).isUndefined() ? 2 : convert<IDLUnsignedLong>(*state, state->uncheckedArgument(1), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto numberOfOutputChannels = state->argument(2).isUndefined() ? 2 : convert<IDLUnsignedLong>(*state, state->uncheckedArgument(2), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<ScriptProcessorNode>>(*state, *castedThis->globalObject(), throwScope, impl.createScriptProcessor(WTFMove(bufferSize), WTFMove(numberOfInputChannels), WTFMove(numberOfOutputChannels))));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateOscillatorCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateOscillator(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateOscillatorCaller>(state, "createOscillator");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateOscillatorCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    return JSValue::encode(toJS<IDLInterface<OscillatorNode>>(*state, *castedThis->globalObject(), impl.createOscillator()));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreatePeriodicWaveCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreatePeriodicWave(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreatePeriodicWaveCaller>(state, "createPeriodicWave");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreatePeriodicWaveCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    if (UNLIKELY(state->argumentCount() < 2))
        return throwVMError(state, throwScope, createNotEnoughArgumentsError(state));
    auto real = convert<IDLInterface<Float32Array>>(*state, state->uncheckedArgument(0), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentTypeError(state, scope, 0, "real", "webkitAudioContext", "createPeriodicWave", "Float32Array"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    auto imag = convert<IDLInterface<Float32Array>>(*state, state->uncheckedArgument(1), [](JSC::ExecState& state, JSC::ThrowScope& scope) { throwArgumentTypeError(state, scope, 1, "imag", "webkitAudioContext", "createPeriodicWave", "Float32Array"); });
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<PeriodicWave>>(*state, *castedThis->globalObject(), throwScope, impl.createPeriodicWave(real.releaseNonNull(), imag.releaseNonNull())));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateChannelSplitterCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateChannelSplitter(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateChannelSplitterCaller>(state, "createChannelSplitter");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateChannelSplitterCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    auto numberOfOutputs = state->argument(0).isUndefined() ? 6 : convert<IDLUnsignedLong>(*state, state->uncheckedArgument(0), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<ChannelSplitterNode>>(*state, *castedThis->globalObject(), throwScope, impl.createChannelSplitter(WTFMove(numberOfOutputs))));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateChannelMergerCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionCreateChannelMerger(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionCreateChannelMergerCaller>(state, "createChannelMerger");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionCreateChannelMergerCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    auto numberOfInputs = state->argument(0).isUndefined() ? 6 : convert<IDLUnsignedLong>(*state, state->uncheckedArgument(0), IntegerConversionConfiguration::Normal);
    RETURN_IF_EXCEPTION(throwScope, encodedJSValue());
    return JSValue::encode(toJS<IDLInterface<ChannelMergerNode>>(*state, *castedThis->globalObject(), throwScope, impl.createChannelMerger(WTFMove(numberOfInputs))));
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionStartRenderingCaller(JSC::ExecState*, JSAudioContext*, JSC::ThrowScope&);

EncodedJSValue JSC_HOST_CALL jsAudioContextPrototypeFunctionStartRendering(ExecState* state)
{
    return BindingCaller<JSAudioContext>::callOperation<jsAudioContextPrototypeFunctionStartRenderingCaller>(state, "startRendering");
}

static inline JSC::EncodedJSValue jsAudioContextPrototypeFunctionStartRenderingCaller(JSC::ExecState* state, JSAudioContext* castedThis, JSC::ThrowScope& throwScope)
{
    UNUSED_PARAM(state);
    UNUSED_PARAM(throwScope);
    auto& impl = castedThis->wrapped();
    impl.startRendering();
    return JSValue::encode(jsUndefined());
}

void JSAudioContext::visitChildren(JSCell* cell, SlotVisitor& visitor)
{
    auto* thisObject = jsCast<JSAudioContext*>(cell);
    ASSERT_GC_OBJECT_INHERITS(thisObject, info());
    Base::visitChildren(thisObject, visitor);
    thisObject->wrapped().visitJSEventListeners(visitor);
}

bool JSAudioContextOwner::isReachableFromOpaqueRoots(JSC::Handle<JSC::Unknown> handle, void*, SlotVisitor& visitor)
{
    auto* jsAudioContext = jsCast<JSAudioContext*>(handle.slot()->asCell());
    if (jsAudioContext->wrapped().hasPendingActivity())
        return true;
    if (jsAudioContext->wrapped().isFiringEventListeners())
        return true;
    UNUSED_PARAM(visitor);
    return false;
}

void JSAudioContextOwner::finalize(JSC::Handle<JSC::Unknown> handle, void* context)
{
    auto* jsAudioContext = static_cast<JSAudioContext*>(handle.slot()->asCell());
    auto& world = *static_cast<DOMWrapperWorld*>(context);
    uncacheWrapper(world, &jsAudioContext->wrapped(), jsAudioContext);
}

#if ENABLE(BINDING_INTEGRITY)
#if PLATFORM(WIN)
#pragma warning(disable: 4483)
extern "C" { extern void (*const __identifier("??_7AudioContext@WebCore@@6B@")[])(); }
#else
extern "C" { extern void* _ZTVN7WebCore12AudioContextE[]; }
#endif
#endif

JSC::JSValue toJSNewlyCreated(JSC::ExecState*, JSDOMGlobalObject* globalObject, Ref<AudioContext>&& impl)
{

#if ENABLE(BINDING_INTEGRITY)
    void* actualVTablePointer = *(reinterpret_cast<void**>(impl.ptr()));
#if PLATFORM(WIN)
    void* expectedVTablePointer = reinterpret_cast<void*>(__identifier("??_7AudioContext@WebCore@@6B@"));
#else
    void* expectedVTablePointer = &_ZTVN7WebCore12AudioContextE[2];
#if COMPILER(CLANG)
    // If this fails AudioContext does not have a vtable, so you need to add the
    // ImplementationLacksVTable attribute to the interface definition
    static_assert(__is_polymorphic(AudioContext), "AudioContext is not polymorphic");
#endif
#endif
    // If you hit this assertion you either have a use after free bug, or
    // AudioContext has subclasses. If AudioContext has subclasses that get passed
    // to toJS() we currently require AudioContext you to opt out of binding hardening
    // by adding the SkipVTableValidation attribute to the interface IDL definition
    RELEASE_ASSERT(actualVTablePointer == expectedVTablePointer);
#endif
    return createWrapper<AudioContext>(globalObject, WTFMove(impl));
}

JSC::JSValue toJS(JSC::ExecState* state, JSDOMGlobalObject* globalObject, AudioContext& impl)
{
    return wrap(state, globalObject, impl);
}

AudioContext* JSAudioContext::toWrapped(JSC::JSValue value)
{
    if (auto* wrapper = jsDynamicDowncast<JSAudioContext*>(value))
        return &wrapper->wrapped();
    return nullptr;
}

}

#endif // ENABLE(WEB_AUDIO)
